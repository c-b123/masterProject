{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1BJ1uKIavNMzX35VUK3rL2NVviY4opZBQ","authorship_tag":"ABX9TyOmksKW94AYqGUxey6fTQLX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0376b981d91c4a628abd2e1747e7912f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_69ade82cea4f4061890dae1e0a439aed","IPY_MODEL_330d77c0bee949389116bfc26166c740","IPY_MODEL_50fc32c2c82e44a493201c50ec964e47"],"layout":"IPY_MODEL_38bf39fb7172495ea02a86ab0c7e0fa6"}},"69ade82cea4f4061890dae1e0a439aed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_802cd70b3cc64ab29c61f1fcb3eb950c","placeholder":"​","style":"IPY_MODEL_3c6fc233d8ab49dd8553a04103d1fb24","value":"Map: 100%"}},"330d77c0bee949389116bfc26166c740":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aaccea6120c54a3494f52f5199f80b98","max":3200,"min":0,"orientation":"horizontal","style":"IPY_MODEL_353973ddbabd47a2b95b7e088d0821b6","value":3200}},"50fc32c2c82e44a493201c50ec964e47":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0033d177eb54e30ab9f37fd12929bb1","placeholder":"​","style":"IPY_MODEL_3b101b5da6ae4e8287690f2b3c0e780d","value":" 3200/3200 [00:01&lt;00:00, 2677.16 examples/s]"}},"38bf39fb7172495ea02a86ab0c7e0fa6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"802cd70b3cc64ab29c61f1fcb3eb950c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c6fc233d8ab49dd8553a04103d1fb24":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aaccea6120c54a3494f52f5199f80b98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"353973ddbabd47a2b95b7e088d0821b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a0033d177eb54e30ab9f37fd12929bb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b101b5da6ae4e8287690f2b3c0e780d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e199be2881654205ae8952119ef37171":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d9f97295c745446b84dc547342b66b9f","IPY_MODEL_b34d9171f99d4b10a3954fb5a6333f47","IPY_MODEL_eb49e9be3d7246e2a8f2c8cec110ab82"],"layout":"IPY_MODEL_cd164376d95f4dd38ea46f23c14cfd92"}},"d9f97295c745446b84dc547342b66b9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f32f47327731471db1c413071cbe138b","placeholder":"​","style":"IPY_MODEL_74f0afc97de84e83a53a5ec226e94905","value":"Map: 100%"}},"b34d9171f99d4b10a3954fb5a6333f47":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae5a8ff4518f4d1bb683b19fe60935ae","max":800,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8bff8cea8bc94d51a5c0be51c9dd390f","value":800}},"eb49e9be3d7246e2a8f2c8cec110ab82":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a57a031e62d54795ae69963d54076901","placeholder":"​","style":"IPY_MODEL_a8e5ff5b46b84bea820f598e6392a396","value":" 800/800 [00:00&lt;00:00, 5141.54 examples/s]"}},"cd164376d95f4dd38ea46f23c14cfd92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f32f47327731471db1c413071cbe138b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74f0afc97de84e83a53a5ec226e94905":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae5a8ff4518f4d1bb683b19fe60935ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bff8cea8bc94d51a5c0be51c9dd390f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a57a031e62d54795ae69963d54076901":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8e5ff5b46b84bea820f598e6392a396":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5896330cf6564e5390131dacdec1d014":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_07bfc4a2426643bb87c76aeacc959c01","IPY_MODEL_65b2407c49064004a430b8497fe9596a"],"layout":"IPY_MODEL_31b854dc400548e58a3a22661c31bcd0"}},"07bfc4a2426643bb87c76aeacc959c01":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e41fdac600d49f89a9a40f3c4f228dd","placeholder":"​","style":"IPY_MODEL_dfdca734cf534e5eafa560a2fbb275ff","value":"0.010 MB of 0.020 MB uploaded (0.000 MB deduped)\r"}},"65b2407c49064004a430b8497fe9596a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_d52ebff61348498493926ade2e228b69","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e1af37b258944877abd5e2ac449627f0","value":0.5316737698566447}},"31b854dc400548e58a3a22661c31bcd0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e41fdac600d49f89a9a40f3c4f228dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfdca734cf534e5eafa560a2fbb275ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d52ebff61348498493926ade2e228b69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1af37b258944877abd5e2ac449627f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"PTcdiwErn6Kn"},"outputs":[],"source":["%%capture\n","! pip install transformers datasets evaluate\n","! pip install accelerate\n","! pip install --upgrade accelerate\n","! pip install huggingface_hub\n","! pip install wandb"]},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","\n","notebook_login()"],"metadata":{"id":"Xiogk1vfoDs7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import wandb\n","wandb.login()\n","\n","%env WANDB_PROJECT=distilBERT_finetuning\n","%env WANDB_LOG_MODEL=true"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"owmAq2n_oDrH","executionInfo":{"status":"ok","timestamp":1690539148001,"user_tz":-120,"elapsed":6319,"user":{"displayName":"Christian Berger","userId":"06598913742130747632"}},"outputId":"8e4e6b8c-e958-40e4-8cc1-ac69fe0cc458"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchristian-159\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"stream","name":"stdout","text":["env: WANDB_PROJECT=distilBERT_finetuning\n","env: WANDB_LOG_MODEL=true\n"]}]},{"cell_type":"code","source":["from datasets import load_dataset, Dataset, ClassLabel\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n","import evaluate\n","import numpy as np\n","import accelerate\n","from transformers import DataCollatorWithPadding\n","\n","# Load data\n","labels = ClassLabel(num_classes=3, names=[\"negative\", \"neutral\", \"positive\"])\n","id2label = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n","label2id = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n","\n","\n","# Load dataset\n","dataset = load_dataset(\"csv\", data_files=\"/content/drive/MyDrive/masterProject/av_train.csv\")\n","dataset = dataset.rename_column(\"finBERT\", \"label\")\n","dataset = dataset.rename_column(\"summary\", \"text\")\n","\n","# Split into 80% training and 20% validation\n","dataset = dataset[\"train\"].train_test_split(train_size=0.8)\n","\n","# Tokenize dataset using distilbert-base-uncased\n","tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n","\n","\n","def tokenize_function(examples):\n","    examples[\"label\"] = labels.str2int(examples[\"label\"])\n","    return tokenizer(examples[\"text\"], padding=True, truncation=True)\n","\n","\n","tokenized_train = dataset[\"train\"].map(tokenize_function, batched=True)\n","tokenized_test = dataset[\"test\"].map(tokenize_function, batched=True)\n","\n","# Convert to PyTorch tensors for faster training\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["0376b981d91c4a628abd2e1747e7912f","69ade82cea4f4061890dae1e0a439aed","330d77c0bee949389116bfc26166c740","50fc32c2c82e44a493201c50ec964e47","38bf39fb7172495ea02a86ab0c7e0fa6","802cd70b3cc64ab29c61f1fcb3eb950c","3c6fc233d8ab49dd8553a04103d1fb24","aaccea6120c54a3494f52f5199f80b98","353973ddbabd47a2b95b7e088d0821b6","a0033d177eb54e30ab9f37fd12929bb1","3b101b5da6ae4e8287690f2b3c0e780d","e199be2881654205ae8952119ef37171","d9f97295c745446b84dc547342b66b9f","b34d9171f99d4b10a3954fb5a6333f47","eb49e9be3d7246e2a8f2c8cec110ab82","cd164376d95f4dd38ea46f23c14cfd92","f32f47327731471db1c413071cbe138b","74f0afc97de84e83a53a5ec226e94905","ae5a8ff4518f4d1bb683b19fe60935ae","8bff8cea8bc94d51a5c0be51c9dd390f","a57a031e62d54795ae69963d54076901","a8e5ff5b46b84bea820f598e6392a396"]},"id":"2L0yXGVYoDol","executionInfo":{"status":"ok","timestamp":1690539170063,"user_tz":-120,"elapsed":16461,"user":{"displayName":"Christian Berger","userId":"06598913742130747632"}},"outputId":"24b7df4d-ade6-454b-ec43-95ebb1ca309c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/3200 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0376b981d91c4a628abd2e1747e7912f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/800 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e199be2881654205ae8952119ef37171"}},"metadata":{}}]},{"cell_type":"code","source":["def model_init():\n","  model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", id2label=id2label, label2id=label2id, num_labels=3)\n","  return model"],"metadata":{"id":"AV90PrRpp3do"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sweep_config = {\n","    'method': 'grid',\n","    'name': 'distilBERT_finetuning',\n","    'metric': {\n","        'goal': 'maximize',\n","        'name': 'eval/f1'\n","        },\n","    'parameters': {\n","        'per_device_train_batch_size': {\n","            'values': [32, 64, 128]\n","            },\n","        'learning_rate': {\n","            'values': [1e-5, 3e-5, 5e-5]\n","        },\n","        'weight_decay': {\n","            'values': [0.0, 0.25]\n","        }\n","     },\n","    'early_terminate': {\n","        'type': 'hyperband',\n","        'min_iter': 5\n","    }\n","}"],"metadata":{"id":"RHpWfBQqoDmb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sweep_id = wandb.sweep(sweep_config, project='distilBERT_finetuning')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DkkNmJ7YrVB5","executionInfo":{"status":"ok","timestamp":1690539170505,"user_tz":-120,"elapsed":449,"user":{"displayName":"Christian Berger","userId":"06598913742130747632"}},"outputId":"9dcad1b3-240a-421e-8304-18f6f1d2a291"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Create sweep with ID: uahb15q7\n","Sweep URL: https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7\n"]}]},{"cell_type":"code","source":["def compute_metrics(eval_preds):\n","  metrics = dict()\n","\n","  accuracy_metric = evaluate.load(\"accuracy\")\n","  f1_metric = evaluate.load(\"f1\")\n","\n","\n","  logits = eval_preds.predictions\n","  labels = eval_preds.label_ids\n","  preds = np.argmax(logits, axis=-1)\n","\n","  metrics.update(accuracy_metric.compute(predictions=preds, references=labels))\n","  metrics.update(f1_metric.compute(predictions=preds, references=labels, average='weighted'))\n","\n","  return metrics\n","\n","\n","\n","def train(config=None):\n","  with wandb.init(config=config):\n","    # set sweep configuration\n","    config = wandb.config\n","\n","\n","    # set training arguments\n","    training_args = TrainingArguments(\n","        output_dir=\"distilBERT_finetuning\",\n","        learning_rate=config.learning_rate,\n","        per_device_train_batch_size=config.per_device_train_batch_size,\n","        per_device_eval_batch_size=16,\n","        num_train_epochs=1,\n","        weight_decay=config.weight_decay,\n","        evaluation_strategy=\"steps\",\n","        report_to=\"wandb\",\n","        eval_steps=25,\n","        max_steps = 200,\n","        save_steps = 0,\n","        load_best_model_at_end=True,\n","        logging_steps=1\n","    )\n","\n","\n","    # define training loop\n","    trainer = Trainer(\n","        model_init=model_init,\n","        args=training_args,\n","        train_dataset=tokenized_train,\n","        eval_dataset=tokenized_test,\n","        tokenizer=tokenizer,\n","        data_collator=data_collator,\n","        compute_metrics=compute_metrics,\n","    )\n","\n","\n","    # start training loop\n","    trainer.train()"],"metadata":{"id":"msy3JDzlqjrS","executionInfo":{"status":"ok","timestamp":1690714802349,"user_tz":-120,"elapsed":8,"user":{"displayName":"Christian Berger","userId":"06598913742130747632"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["wandb.agent(sweep_id, train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["5896330cf6564e5390131dacdec1d014","07bfc4a2426643bb87c76aeacc959c01","65b2407c49064004a430b8497fe9596a","31b854dc400548e58a3a22661c31bcd0","8e41fdac600d49f89a9a40f3c4f228dd","dfdca734cf534e5eafa560a2fbb275ff","d52ebff61348498493926ade2e228b69","e1af37b258944877abd5e2ac449627f0"]},"id":"r_UIRgfyrf44","executionInfo":{"status":"ok","timestamp":1690544140258,"user_tz":-120,"elapsed":964662,"user":{"displayName":"Christian Berger","userId":"06598913742130747632"}},"outputId":"8c8fbdf8-943e-4002-aac6-5a32a06a8af9"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xh8a03lp with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tper_device_train_batch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230728_101257-xh8a03lp</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/xh8a03lp' target=\"_blank\">electric-sweep-1</a></strong> to <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/xh8a03lp' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/xh8a03lp</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'per_device_train_batch_size' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n","You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/200 02:16, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>1.056800</td>\n","      <td>1.052234</td>\n","      <td>0.423750</td>\n","      <td>0.258076</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.939300</td>\n","      <td>0.952162</td>\n","      <td>0.580000</td>\n","      <td>0.503611</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.812200</td>\n","      <td>0.809131</td>\n","      <td>0.717500</td>\n","      <td>0.690900</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.757500</td>\n","      <td>0.710850</td>\n","      <td>0.740000</td>\n","      <td>0.726773</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.611700</td>\n","      <td>0.647887</td>\n","      <td>0.753750</td>\n","      <td>0.741447</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.521800</td>\n","      <td>0.613825</td>\n","      <td>0.778750</td>\n","      <td>0.774719</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.646200</td>\n","      <td>0.594484</td>\n","      <td>0.781250</td>\n","      <td>0.776899</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.491800</td>\n","      <td>0.590579</td>\n","      <td>0.778750</td>\n","      <td>0.774286</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▄▇▇▇███</td></tr><tr><td>eval/f1</td><td>▁▄▇▇████</td></tr><tr><td>eval/loss</td><td>█▆▄▃▂▁▁▁</td></tr><tr><td>eval/runtime</td><td>█▁▁▁▁▄▂▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▇█▇█▄▇█</td></tr><tr><td>eval/steps_per_second</td><td>▁▇█▇█▄▇█</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>██▇██▇▇▇▇▆▇▆▇▅▅▄▆▄▄▃▄▄▂▃▂▂▂▃▂▂▂▃▁▂▁▃▁▁▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.77875</td></tr><tr><td>eval/f1</td><td>0.77429</td></tr><tr><td>eval/loss</td><td>0.59058</td></tr><tr><td>eval/runtime</td><td>3.8165</td></tr><tr><td>eval/samples_per_second</td><td>209.615</td></tr><tr><td>eval/steps_per_second</td><td>13.101</td></tr><tr><td>train/epoch</td><td>2.0</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4918</td></tr><tr><td>train/total_flos</td><td>314615682432000.0</td></tr><tr><td>train/train_loss</td><td>0.77644</td></tr><tr><td>train/train_runtime</td><td>134.4357</td></tr><tr><td>train/train_samples_per_second</td><td>47.606</td></tr><tr><td>train/train_steps_per_second</td><td>1.488</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">electric-sweep-1</strong> at: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/xh8a03lp' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/xh8a03lp</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230728_101257-xh8a03lp/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1d9md36s with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tper_device_train_batch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.25\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230728_101552-1d9md36s</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/1d9md36s' target=\"_blank\">usual-sweep-2</a></strong> to <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/1d9md36s' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/1d9md36s</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'per_device_train_batch_size' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/200 02:13, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>1.056700</td>\n","      <td>1.052248</td>\n","      <td>0.423750</td>\n","      <td>0.258076</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.939300</td>\n","      <td>0.952170</td>\n","      <td>0.580000</td>\n","      <td>0.503484</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.812200</td>\n","      <td>0.809214</td>\n","      <td>0.718750</td>\n","      <td>0.691987</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.757700</td>\n","      <td>0.711014</td>\n","      <td>0.740000</td>\n","      <td>0.726773</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.611500</td>\n","      <td>0.648125</td>\n","      <td>0.753750</td>\n","      <td>0.741447</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.522200</td>\n","      <td>0.614106</td>\n","      <td>0.778750</td>\n","      <td>0.774719</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.645800</td>\n","      <td>0.594745</td>\n","      <td>0.781250</td>\n","      <td>0.776899</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.491800</td>\n","      <td>0.590833</td>\n","      <td>0.777500</td>\n","      <td>0.772887</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▄▇▇▇███</td></tr><tr><td>eval/f1</td><td>▁▄▇▇████</td></tr><tr><td>eval/loss</td><td>█▆▄▃▂▁▁▁</td></tr><tr><td>eval/runtime</td><td>▁▃▂▃▃▇▇█</td></tr><tr><td>eval/samples_per_second</td><td>█▆▆▆▆▂▂▁</td></tr><tr><td>eval/steps_per_second</td><td>█▆▇▆▆▂▂▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>██▇██▇▇▇▇▆▇▆▇▅▅▄▆▄▄▃▄▄▂▃▂▂▂▃▂▂▂▃▁▂▁▃▁▁▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.7775</td></tr><tr><td>eval/f1</td><td>0.77289</td></tr><tr><td>eval/loss</td><td>0.59083</td></tr><tr><td>eval/runtime</td><td>3.8453</td></tr><tr><td>eval/samples_per_second</td><td>208.047</td></tr><tr><td>eval/steps_per_second</td><td>13.003</td></tr><tr><td>train/epoch</td><td>2.0</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4918</td></tr><tr><td>train/total_flos</td><td>314615682432000.0</td></tr><tr><td>train/train_loss</td><td>0.77652</td></tr><tr><td>train/train_runtime</td><td>129.832</td></tr><tr><td>train/train_samples_per_second</td><td>49.294</td></tr><tr><td>train/train_steps_per_second</td><td>1.54</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">usual-sweep-2</strong> at: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/1d9md36s' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/1d9md36s</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230728_101552-1d9md36s/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tiqz2qvq with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tper_device_train_batch_size: 64\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230728_101833-tiqz2qvq</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/tiqz2qvq' target=\"_blank\">dulcet-sweep-3</a></strong> to <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/tiqz2qvq' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/tiqz2qvq</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'per_device_train_batch_size' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/200 03:37, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>1.028000</td>\n","      <td>1.035053</td>\n","      <td>0.450000</td>\n","      <td>0.312050</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.881800</td>\n","      <td>0.866572</td>\n","      <td>0.713750</td>\n","      <td>0.689946</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.699000</td>\n","      <td>0.704664</td>\n","      <td>0.758750</td>\n","      <td>0.748799</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.682200</td>\n","      <td>0.612762</td>\n","      <td>0.771250</td>\n","      <td>0.762123</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.609900</td>\n","      <td>0.555349</td>\n","      <td>0.805000</td>\n","      <td>0.802196</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.512100</td>\n","      <td>0.530686</td>\n","      <td>0.806250</td>\n","      <td>0.805273</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.460900</td>\n","      <td>0.514426</td>\n","      <td>0.810000</td>\n","      <td>0.808335</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.436900</td>\n","      <td>0.511185</td>\n","      <td>0.800000</td>\n","      <td>0.798136</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▇▇████</td></tr><tr><td>eval/f1</td><td>▁▆▇▇████</td></tr><tr><td>eval/loss</td><td>█▆▄▂▂▁▁▁</td></tr><tr><td>eval/runtime</td><td>▄▁▅▂▁█▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▄█▃▇█▁██</td></tr><tr><td>eval/steps_per_second</td><td>▄█▃▇█▁██</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>████▇█▇▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▄▃▂▂▃▂▃▁▃▁▂▂▂▁▃▂</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.8</td></tr><tr><td>eval/f1</td><td>0.79814</td></tr><tr><td>eval/loss</td><td>0.51118</td></tr><tr><td>eval/runtime</td><td>3.5232</td></tr><tr><td>eval/samples_per_second</td><td>227.063</td></tr><tr><td>eval/steps_per_second</td><td>14.191</td></tr><tr><td>train/epoch</td><td>4.0</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4369</td></tr><tr><td>train/total_flos</td><td>629231364864000.0</td></tr><tr><td>train/train_loss</td><td>0.67973</td></tr><tr><td>train/train_runtime</td><td>213.7042</td></tr><tr><td>train/train_samples_per_second</td><td>59.896</td></tr><tr><td>train/train_steps_per_second</td><td>0.936</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">dulcet-sweep-3</strong> at: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/tiqz2qvq' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/tiqz2qvq</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230728_101833-tiqz2qvq/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ecx6ulv4 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tper_device_train_batch_size: 64\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.25\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230728_102245-ecx6ulv4</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/ecx6ulv4' target=\"_blank\">winter-sweep-4</a></strong> to <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/ecx6ulv4' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/ecx6ulv4</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'per_device_train_batch_size' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/200 03:38, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>1.028000</td>\n","      <td>1.035008</td>\n","      <td>0.452500</td>\n","      <td>0.317063</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.881800</td>\n","      <td>0.866543</td>\n","      <td>0.713750</td>\n","      <td>0.689946</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.698800</td>\n","      <td>0.704613</td>\n","      <td>0.758750</td>\n","      <td>0.748799</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.682200</td>\n","      <td>0.612842</td>\n","      <td>0.771250</td>\n","      <td>0.762123</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.609900</td>\n","      <td>0.555405</td>\n","      <td>0.805000</td>\n","      <td>0.802196</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.512300</td>\n","      <td>0.530730</td>\n","      <td>0.805000</td>\n","      <td>0.804063</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.460900</td>\n","      <td>0.514515</td>\n","      <td>0.808750</td>\n","      <td>0.807115</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.436800</td>\n","      <td>0.511236</td>\n","      <td>0.800000</td>\n","      <td>0.798136</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▇▇████</td></tr><tr><td>eval/f1</td><td>▁▆▇▇████</td></tr><tr><td>eval/loss</td><td>█▆▄▂▂▁▁▁</td></tr><tr><td>eval/runtime</td><td>▁█▅▁▃▄▁▅</td></tr><tr><td>eval/samples_per_second</td><td>█▁▄█▆▅█▄</td></tr><tr><td>eval/steps_per_second</td><td>█▁▄█▆▅█▄</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>████▇█▇▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▄▃▂▂▃▂▃▁▃▁▂▂▂▁▃▂</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.8</td></tr><tr><td>eval/f1</td><td>0.79814</td></tr><tr><td>eval/loss</td><td>0.51124</td></tr><tr><td>eval/runtime</td><td>3.8791</td></tr><tr><td>eval/samples_per_second</td><td>206.231</td></tr><tr><td>eval/steps_per_second</td><td>12.889</td></tr><tr><td>train/epoch</td><td>4.0</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4368</td></tr><tr><td>train/total_flos</td><td>629231364864000.0</td></tr><tr><td>train/train_loss</td><td>0.67971</td></tr><tr><td>train/train_runtime</td><td>214.6041</td></tr><tr><td>train/train_samples_per_second</td><td>59.645</td></tr><tr><td>train/train_steps_per_second</td><td>0.932</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">winter-sweep-4</strong> at: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/ecx6ulv4' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/ecx6ulv4</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230728_102245-ecx6ulv4/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6r0af1ns with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tper_device_train_batch_size: 128\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230728_102653-6r0af1ns</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/6r0af1ns' target=\"_blank\">jolly-sweep-5</a></strong> to <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/6r0af1ns' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/6r0af1ns</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'per_device_train_batch_size' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='156' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [156/200 05:03 < 01:26, 0.51 it/s, Epoch 6.20/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>1.021100</td>\n","      <td>1.001426</td>\n","      <td>0.478750</td>\n","      <td>0.365863</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.762500</td>\n","      <td>0.774662</td>\n","      <td>0.718750</td>\n","      <td>0.687657</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.652500</td>\n","      <td>0.622844</td>\n","      <td>0.767500</td>\n","      <td>0.758020</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.492400</td>\n","      <td>0.549649</td>\n","      <td>0.788750</td>\n","      <td>0.784697</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.434200</td>\n","      <td>0.499853</td>\n","      <td>0.797500</td>\n","      <td>0.796222</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.446800</td>\n","      <td>0.469137</td>\n","      <td>0.812500</td>\n","      <td>0.811873</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5896330cf6564e5390131dacdec1d014","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▇███</td></tr><tr><td>eval/f1</td><td>▁▆▇███</td></tr><tr><td>eval/loss</td><td>█▅▃▂▁▁</td></tr><tr><td>eval/runtime</td><td>▃▃▄█▂▁</td></tr><tr><td>eval/samples_per_second</td><td>▆▆▅▁▇█</td></tr><tr><td>eval/steps_per_second</td><td>▆▆▅▁▇█</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█████▇▇▇▇▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▃▂▂▂▁▁▂▂▁▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.8125</td></tr><tr><td>eval/f1</td><td>0.81187</td></tr><tr><td>eval/loss</td><td>0.46914</td></tr><tr><td>eval/runtime</td><td>3.5017</td></tr><tr><td>eval/samples_per_second</td><td>228.463</td></tr><tr><td>eval/steps_per_second</td><td>14.279</td></tr><tr><td>train/epoch</td><td>6.2</td></tr><tr><td>train/global_step</td><td>155</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3385</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">jolly-sweep-5</strong> at: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/6r0af1ns' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/6r0af1ns</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230728_102653-6r0af1ns/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4offykpj with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tper_device_train_batch_size: 128\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.25\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230728_103215-4offykpj</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/4offykpj' target=\"_blank\">bright-sweep-6</a></strong> to <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/4offykpj' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/4offykpj</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'per_device_train_batch_size' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/200 06:37, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>1.021100</td>\n","      <td>1.001449</td>\n","      <td>0.478750</td>\n","      <td>0.365863</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.762700</td>\n","      <td>0.774815</td>\n","      <td>0.718750</td>\n","      <td>0.687657</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.652600</td>\n","      <td>0.623001</td>\n","      <td>0.768750</td>\n","      <td>0.759547</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.492500</td>\n","      <td>0.549699</td>\n","      <td>0.788750</td>\n","      <td>0.784697</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.434200</td>\n","      <td>0.499883</td>\n","      <td>0.797500</td>\n","      <td>0.796222</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.446900</td>\n","      <td>0.469175</td>\n","      <td>0.813750</td>\n","      <td>0.813088</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.342800</td>\n","      <td>0.455284</td>\n","      <td>0.820000</td>\n","      <td>0.819120</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.331600</td>\n","      <td>0.452684</td>\n","      <td>0.818750</td>\n","      <td>0.818466</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▇▇████</td></tr><tr><td>eval/f1</td><td>▁▆▇▇████</td></tr><tr><td>eval/loss</td><td>█▅▃▂▂▁▁▁</td></tr><tr><td>eval/runtime</td><td>▅▁▄▁▄▆▃█</td></tr><tr><td>eval/samples_per_second</td><td>▄█▅█▅▃▆▁</td></tr><tr><td>eval/steps_per_second</td><td>▄█▅█▅▃▆▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>████▇▇▇▆▅▆▅▄▄▄▄▃▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▂▁▂▁▁▂▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.81875</td></tr><tr><td>eval/f1</td><td>0.81847</td></tr><tr><td>eval/loss</td><td>0.45268</td></tr><tr><td>eval/runtime</td><td>3.5753</td></tr><tr><td>eval/samples_per_second</td><td>223.758</td></tr><tr><td>eval/steps_per_second</td><td>13.985</td></tr><tr><td>train/epoch</td><td>8.0</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3316</td></tr><tr><td>train/total_flos</td><td>1258462729728000.0</td></tr><tr><td>train/train_loss</td><td>0.59365</td></tr><tr><td>train/train_runtime</td><td>394.8097</td></tr><tr><td>train/train_samples_per_second</td><td>64.841</td></tr><tr><td>train/train_steps_per_second</td><td>0.507</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">bright-sweep-6</strong> at: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/4offykpj' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/4offykpj</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230728_103215-4offykpj/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0pr4qxhl with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tper_device_train_batch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230728_103922-0pr4qxhl</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/0pr4qxhl' target=\"_blank\">lucky-sweep-7</a></strong> to <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/0pr4qxhl' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/0pr4qxhl</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'per_device_train_batch_size' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/200 02:11, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>0.895800</td>\n","      <td>0.868266</td>\n","      <td>0.696250</td>\n","      <td>0.684205</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.528100</td>\n","      <td>0.585604</td>\n","      <td>0.783750</td>\n","      <td>0.775582</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.511900</td>\n","      <td>0.487917</td>\n","      <td>0.803750</td>\n","      <td>0.802552</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.615100</td>\n","      <td>0.458494</td>\n","      <td>0.823750</td>\n","      <td>0.825314</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.187600</td>\n","      <td>0.439527</td>\n","      <td>0.820000</td>\n","      <td>0.819723</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.181400</td>\n","      <td>0.412543</td>\n","      <td>0.845000</td>\n","      <td>0.845167</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.406400</td>\n","      <td>0.406956</td>\n","      <td>0.835000</td>\n","      <td>0.834365</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.158200</td>\n","      <td>0.401713</td>\n","      <td>0.838750</td>\n","      <td>0.838654</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▆▇▇███</td></tr><tr><td>eval/f1</td><td>▁▅▆▇▇███</td></tr><tr><td>eval/loss</td><td>█▄▂▂▂▁▁▁</td></tr><tr><td>eval/runtime</td><td>▁█▄▃▃▄▄▄</td></tr><tr><td>eval/samples_per_second</td><td>█▁▅▆▆▅▅▅</td></tr><tr><td>eval/steps_per_second</td><td>█▁▅▆▆▅▅▅</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>██▇▇▇▆▆▅▅▄▅▄▄▄▃▄▆▂▃▃▂▂▂▂▂▂▄▂▁▃▁▃▂▃▂▂▂▁▃▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.83875</td></tr><tr><td>eval/f1</td><td>0.83865</td></tr><tr><td>eval/loss</td><td>0.40171</td></tr><tr><td>eval/runtime</td><td>3.5138</td></tr><tr><td>eval/samples_per_second</td><td>227.675</td></tr><tr><td>eval/steps_per_second</td><td>14.23</td></tr><tr><td>train/epoch</td><td>2.0</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1582</td></tr><tr><td>train/total_flos</td><td>314615682432000.0</td></tr><tr><td>train/train_loss</td><td>0.49689</td></tr><tr><td>train/train_runtime</td><td>127.825</td></tr><tr><td>train/train_samples_per_second</td><td>50.068</td></tr><tr><td>train/train_steps_per_second</td><td>1.565</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">lucky-sweep-7</strong> at: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/0pr4qxhl' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/0pr4qxhl</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230728_103922-0pr4qxhl/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9o0dzddn with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tper_device_train_batch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.25\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230728_104201-9o0dzddn</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/9o0dzddn' target=\"_blank\">giddy-sweep-8</a></strong> to <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/9o0dzddn' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/9o0dzddn</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'per_device_train_batch_size' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/200 02:12, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>0.895800</td>\n","      <td>0.868363</td>\n","      <td>0.697500</td>\n","      <td>0.685420</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.528700</td>\n","      <td>0.585707</td>\n","      <td>0.782500</td>\n","      <td>0.774095</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.510900</td>\n","      <td>0.487741</td>\n","      <td>0.803750</td>\n","      <td>0.802552</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.615400</td>\n","      <td>0.458891</td>\n","      <td>0.822500</td>\n","      <td>0.824092</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.186600</td>\n","      <td>0.440237</td>\n","      <td>0.818750</td>\n","      <td>0.818463</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.182700</td>\n","      <td>0.413064</td>\n","      <td>0.842500</td>\n","      <td>0.842771</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.409500</td>\n","      <td>0.407237</td>\n","      <td>0.836250</td>\n","      <td>0.835611</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.158000</td>\n","      <td>0.401882</td>\n","      <td>0.838750</td>\n","      <td>0.838654</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▆▇▇███</td></tr><tr><td>eval/f1</td><td>▁▅▆▇▇███</td></tr><tr><td>eval/loss</td><td>█▄▂▂▂▁▁▁</td></tr><tr><td>eval/runtime</td><td>▁▇█▁▅▁█▇</td></tr><tr><td>eval/samples_per_second</td><td>█▂▁█▄█▁▂</td></tr><tr><td>eval/steps_per_second</td><td>█▂▁█▄█▁▂</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>██▇▇▇▆▆▅▅▄▅▄▄▄▃▄▆▂▃▃▂▂▂▂▂▂▃▂▁▃▁▃▂▃▂▂▂▁▃▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.83875</td></tr><tr><td>eval/f1</td><td>0.83865</td></tr><tr><td>eval/loss</td><td>0.40188</td></tr><tr><td>eval/runtime</td><td>3.5327</td></tr><tr><td>eval/samples_per_second</td><td>226.454</td></tr><tr><td>eval/steps_per_second</td><td>14.153</td></tr><tr><td>train/epoch</td><td>2.0</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.158</td></tr><tr><td>train/total_flos</td><td>314615682432000.0</td></tr><tr><td>train/train_loss</td><td>0.49695</td></tr><tr><td>train/train_runtime</td><td>128.1432</td></tr><tr><td>train/train_samples_per_second</td><td>49.944</td></tr><tr><td>train/train_steps_per_second</td><td>1.561</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">giddy-sweep-8</strong> at: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/9o0dzddn' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/9o0dzddn</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230728_104201-9o0dzddn/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ujpcnjs0 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tper_device_train_batch_size: 64\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230728_104441-ujpcnjs0</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/ujpcnjs0' target=\"_blank\">vibrant-sweep-9</a></strong> to <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/ujpcnjs0' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/ujpcnjs0</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'per_device_train_batch_size' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/200 03:37, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>0.722700</td>\n","      <td>0.762208</td>\n","      <td>0.690000</td>\n","      <td>0.637717</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.562100</td>\n","      <td>0.532943</td>\n","      <td>0.786250</td>\n","      <td>0.788836</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.390000</td>\n","      <td>0.439047</td>\n","      <td>0.831250</td>\n","      <td>0.830141</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.443700</td>\n","      <td>0.407983</td>\n","      <td>0.832500</td>\n","      <td>0.831303</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.233800</td>\n","      <td>0.400854</td>\n","      <td>0.843750</td>\n","      <td>0.844148</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.160100</td>\n","      <td>0.390418</td>\n","      <td>0.848750</td>\n","      <td>0.848437</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.162300</td>\n","      <td>0.392975</td>\n","      <td>0.846250</td>\n","      <td>0.846328</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.143400</td>\n","      <td>0.393332</td>\n","      <td>0.846250</td>\n","      <td>0.846213</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▇▇████</td></tr><tr><td>eval/f1</td><td>▁▆▇▇████</td></tr><tr><td>eval/loss</td><td>█▄▂▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▂█▁▂▇▁▃█</td></tr><tr><td>eval/samples_per_second</td><td>▇▁█▇▂█▅▁</td></tr><tr><td>eval/steps_per_second</td><td>▇▁█▇▂█▅▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>███▇▆▆▅▄▅▄▅▃▄▃▃▃▃▃▂▃▂▂▂▂▃▂▂▂▂▂▂▁▁▂▂▁▁▁▃▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.84625</td></tr><tr><td>eval/f1</td><td>0.84621</td></tr><tr><td>eval/loss</td><td>0.39333</td></tr><tr><td>eval/runtime</td><td>3.9152</td></tr><tr><td>eval/samples_per_second</td><td>204.33</td></tr><tr><td>eval/steps_per_second</td><td>12.771</td></tr><tr><td>train/epoch</td><td>4.0</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1434</td></tr><tr><td>train/total_flos</td><td>629231364864000.0</td></tr><tr><td>train/train_loss</td><td>0.39647</td></tr><tr><td>train/train_runtime</td><td>213.4915</td></tr><tr><td>train/train_samples_per_second</td><td>59.956</td></tr><tr><td>train/train_steps_per_second</td><td>0.937</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">vibrant-sweep-9</strong> at: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/ujpcnjs0' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/ujpcnjs0</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230728_104441-ujpcnjs0/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n9rh1an3 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tper_device_train_batch_size: 64\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.25\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230728_104849-n9rh1an3</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/n9rh1an3' target=\"_blank\">expert-sweep-10</a></strong> to <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/n9rh1an3' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/n9rh1an3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'per_device_train_batch_size' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/200 03:37, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>0.722800</td>\n","      <td>0.762440</td>\n","      <td>0.690000</td>\n","      <td>0.637717</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.562400</td>\n","      <td>0.533505</td>\n","      <td>0.785000</td>\n","      <td>0.787629</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.390000</td>\n","      <td>0.439286</td>\n","      <td>0.828750</td>\n","      <td>0.827717</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.442800</td>\n","      <td>0.407634</td>\n","      <td>0.832500</td>\n","      <td>0.831350</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.234100</td>\n","      <td>0.401212</td>\n","      <td>0.843750</td>\n","      <td>0.844148</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.160700</td>\n","      <td>0.390454</td>\n","      <td>0.847500</td>\n","      <td>0.847209</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.162700</td>\n","      <td>0.393165</td>\n","      <td>0.847500</td>\n","      <td>0.847668</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.143700</td>\n","      <td>0.393368</td>\n","      <td>0.846250</td>\n","      <td>0.846213</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▇▇████</td></tr><tr><td>eval/f1</td><td>▁▆▇▇████</td></tr><tr><td>eval/loss</td><td>█▄▂▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>█▂▅▂▂▇▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▇▃▆▇▂██</td></tr><tr><td>eval/steps_per_second</td><td>▁▇▃▆▇▂██</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>███▇▆▆▅▄▅▄▅▃▄▃▃▃▃▃▂▂▂▂▂▂▃▂▂▂▂▂▂▁▁▂▂▁▁▁▃▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.84625</td></tr><tr><td>eval/f1</td><td>0.84621</td></tr><tr><td>eval/loss</td><td>0.39337</td></tr><tr><td>eval/runtime</td><td>3.5006</td></tr><tr><td>eval/samples_per_second</td><td>228.53</td></tr><tr><td>eval/steps_per_second</td><td>14.283</td></tr><tr><td>train/epoch</td><td>4.0</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1437</td></tr><tr><td>train/total_flos</td><td>629231364864000.0</td></tr><tr><td>train/train_loss</td><td>0.39666</td></tr><tr><td>train/train_runtime</td><td>213.6686</td></tr><tr><td>train/train_samples_per_second</td><td>59.906</td></tr><tr><td>train/train_steps_per_second</td><td>0.936</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">expert-sweep-10</strong> at: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/n9rh1an3' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/n9rh1an3</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230728_104849-n9rh1an3/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 368syhfe with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tper_device_train_batch_size: 128\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230728_105253-368syhfe</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/368syhfe' target=\"_blank\">fiery-sweep-11</a></strong> to <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/368syhfe' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/368syhfe</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'per_device_train_batch_size' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/200 06:37, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>0.709400</td>\n","      <td>0.671746</td>\n","      <td>0.761250</td>\n","      <td>0.755896</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.403700</td>\n","      <td>0.443352</td>\n","      <td>0.822500</td>\n","      <td>0.821827</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.301600</td>\n","      <td>0.399959</td>\n","      <td>0.843750</td>\n","      <td>0.843833</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.183200</td>\n","      <td>0.389825</td>\n","      <td>0.848750</td>\n","      <td>0.847649</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.079600</td>\n","      <td>0.390036</td>\n","      <td>0.865000</td>\n","      <td>0.864738</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.170700</td>\n","      <td>0.405720</td>\n","      <td>0.860000</td>\n","      <td>0.860261</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.059700</td>\n","      <td>0.419935</td>\n","      <td>0.862500</td>\n","      <td>0.862219</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.042800</td>\n","      <td>0.416277</td>\n","      <td>0.865000</td>\n","      <td>0.865166</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▇▇████</td></tr><tr><td>eval/f1</td><td>▁▅▇▇████</td></tr><tr><td>eval/loss</td><td>█▂▁▁▁▁▂▂</td></tr><tr><td>eval/runtime</td><td>▃▂▂▄▂▂▁█</td></tr><tr><td>eval/samples_per_second</td><td>▆▇▇▅▇▇█▁</td></tr><tr><td>eval/steps_per_second</td><td>▆▇▇▅▇▇█▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>██▇▇▆▅▄▄▃▄▃▃▃▂▃▂▃▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.865</td></tr><tr><td>eval/f1</td><td>0.86517</td></tr><tr><td>eval/loss</td><td>0.41628</td></tr><tr><td>eval/runtime</td><td>3.6442</td></tr><tr><td>eval/samples_per_second</td><td>219.529</td></tr><tr><td>eval/steps_per_second</td><td>13.721</td></tr><tr><td>train/epoch</td><td>8.0</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0428</td></tr><tr><td>train/total_flos</td><td>1258462729728000.0</td></tr><tr><td>train/train_loss</td><td>0.28973</td></tr><tr><td>train/train_runtime</td><td>394.4852</td></tr><tr><td>train/train_samples_per_second</td><td>64.895</td></tr><tr><td>train/train_steps_per_second</td><td>0.507</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">fiery-sweep-11</strong> at: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/368syhfe' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/368syhfe</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230728_105253-368syhfe/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: j76ja80z with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tper_device_train_batch_size: 128\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.25\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230728_110001-j76ja80z</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/j76ja80z' target=\"_blank\">vital-sweep-12</a></strong> to <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/j76ja80z' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/j76ja80z</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'per_device_train_batch_size' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/200 06:37, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>0.709400</td>\n","      <td>0.671792</td>\n","      <td>0.760000</td>\n","      <td>0.754455</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.403900</td>\n","      <td>0.443289</td>\n","      <td>0.821250</td>\n","      <td>0.820492</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.301700</td>\n","      <td>0.399752</td>\n","      <td>0.845000</td>\n","      <td>0.845054</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.183600</td>\n","      <td>0.389826</td>\n","      <td>0.847500</td>\n","      <td>0.846305</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.079700</td>\n","      <td>0.389903</td>\n","      <td>0.865000</td>\n","      <td>0.864701</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.170800</td>\n","      <td>0.405276</td>\n","      <td>0.861250</td>\n","      <td>0.861484</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.059700</td>\n","      <td>0.419566</td>\n","      <td>0.862500</td>\n","      <td>0.862219</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.042900</td>\n","      <td>0.415866</td>\n","      <td>0.863750</td>\n","      <td>0.863941</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▇▇████</td></tr><tr><td>eval/f1</td><td>▁▅▇▇████</td></tr><tr><td>eval/loss</td><td>█▂▁▁▁▁▂▂</td></tr><tr><td>eval/runtime</td><td>█▆▄▄▂▂▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▃▅▅▇▇██</td></tr><tr><td>eval/steps_per_second</td><td>▁▃▅▅▇▇██</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>██▇▇▆▅▄▄▃▄▃▃▃▂▃▂▃▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.86375</td></tr><tr><td>eval/f1</td><td>0.86394</td></tr><tr><td>eval/loss</td><td>0.41587</td></tr><tr><td>eval/runtime</td><td>3.5219</td></tr><tr><td>eval/samples_per_second</td><td>227.152</td></tr><tr><td>eval/steps_per_second</td><td>14.197</td></tr><tr><td>train/epoch</td><td>8.0</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0429</td></tr><tr><td>train/total_flos</td><td>1258462729728000.0</td></tr><tr><td>train/train_loss</td><td>0.28995</td></tr><tr><td>train/train_runtime</td><td>395.2471</td></tr><tr><td>train/train_samples_per_second</td><td>64.77</td></tr><tr><td>train/train_steps_per_second</td><td>0.506</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">vital-sweep-12</strong> at: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/j76ja80z' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/j76ja80z</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230728_110001-j76ja80z/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9z2a0ksj with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tper_device_train_batch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230728_110710-9z2a0ksj</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/9z2a0ksj' target=\"_blank\">dry-sweep-13</a></strong> to <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/9z2a0ksj' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/9z2a0ksj</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'per_device_train_batch_size' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/200 02:12, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>0.867100</td>\n","      <td>0.735452</td>\n","      <td>0.690000</td>\n","      <td>0.685211</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.534000</td>\n","      <td>0.567320</td>\n","      <td>0.771250</td>\n","      <td>0.759257</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.476700</td>\n","      <td>0.444425</td>\n","      <td>0.830000</td>\n","      <td>0.828382</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.594800</td>\n","      <td>0.436632</td>\n","      <td>0.816250</td>\n","      <td>0.818139</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.130900</td>\n","      <td>0.432447</td>\n","      <td>0.828750</td>\n","      <td>0.828873</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.081700</td>\n","      <td>0.391767</td>\n","      <td>0.846250</td>\n","      <td>0.846371</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.309700</td>\n","      <td>0.392596</td>\n","      <td>0.840000</td>\n","      <td>0.839566</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.111600</td>\n","      <td>0.397697</td>\n","      <td>0.840000</td>\n","      <td>0.840260</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▇▇▇███</td></tr><tr><td>eval/f1</td><td>▁▄▇▇▇███</td></tr><tr><td>eval/loss</td><td>█▅▂▂▂▁▁▁</td></tr><tr><td>eval/runtime</td><td>▂▅▃▂▂▁▄█</td></tr><tr><td>eval/samples_per_second</td><td>▇▄▆▇▇█▄▁</td></tr><tr><td>eval/steps_per_second</td><td>▇▄▆▇▇█▄▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>██▇▆▆▅▅▅▄▄▅▄▃▃▂▄▆▂▃▃▂▂▂▂▂▁▃▁▁▃▁▂▁▃▂▂▂▁▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.84</td></tr><tr><td>eval/f1</td><td>0.84026</td></tr><tr><td>eval/loss</td><td>0.3977</td></tr><tr><td>eval/runtime</td><td>3.9372</td></tr><tr><td>eval/samples_per_second</td><td>203.193</td></tr><tr><td>eval/steps_per_second</td><td>12.7</td></tr><tr><td>train/epoch</td><td>2.0</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1116</td></tr><tr><td>train/total_flos</td><td>314615682432000.0</td></tr><tr><td>train/train_loss</td><td>0.43005</td></tr><tr><td>train/train_runtime</td><td>128.8668</td></tr><tr><td>train/train_samples_per_second</td><td>49.664</td></tr><tr><td>train/train_steps_per_second</td><td>1.552</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">dry-sweep-13</strong> at: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/9z2a0ksj' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/9z2a0ksj</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230728_110710-9z2a0ksj/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0yjl9okn with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tper_device_train_batch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.25\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230728_110950-0yjl9okn</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/0yjl9okn' target=\"_blank\">vague-sweep-14</a></strong> to <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/0yjl9okn' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/0yjl9okn</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'per_device_train_batch_size' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/200 02:16, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>0.864800</td>\n","      <td>0.732332</td>\n","      <td>0.691250</td>\n","      <td>0.686265</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.528400</td>\n","      <td>0.565112</td>\n","      <td>0.772500</td>\n","      <td>0.760446</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.479800</td>\n","      <td>0.446333</td>\n","      <td>0.826250</td>\n","      <td>0.824740</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.593000</td>\n","      <td>0.438158</td>\n","      <td>0.817500</td>\n","      <td>0.819376</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.128200</td>\n","      <td>0.432959</td>\n","      <td>0.825000</td>\n","      <td>0.825090</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.084800</td>\n","      <td>0.392107</td>\n","      <td>0.848750</td>\n","      <td>0.848853</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.301600</td>\n","      <td>0.392042</td>\n","      <td>0.840000</td>\n","      <td>0.839541</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.112000</td>\n","      <td>0.397911</td>\n","      <td>0.840000</td>\n","      <td>0.840260</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▇▇▇███</td></tr><tr><td>eval/f1</td><td>▁▄▇▇▇███</td></tr><tr><td>eval/loss</td><td>█▅▂▂▂▁▁▁</td></tr><tr><td>eval/runtime</td><td>█▃▃▂▂▂▁▇</td></tr><tr><td>eval/samples_per_second</td><td>▁▆▆▇▇▇█▂</td></tr><tr><td>eval/steps_per_second</td><td>▁▆▆▇▇▇█▂</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>██▇▆▆▅▅▅▄▄▅▄▃▃▂▄▆▂▃▃▂▂▂▂▂▁▃▁▁▃▁▂▁▃▂▂▂▁▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.84</td></tr><tr><td>eval/f1</td><td>0.84026</td></tr><tr><td>eval/loss</td><td>0.39791</td></tr><tr><td>eval/runtime</td><td>3.6703</td></tr><tr><td>eval/samples_per_second</td><td>217.963</td></tr><tr><td>eval/steps_per_second</td><td>13.623</td></tr><tr><td>train/epoch</td><td>2.0</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.112</td></tr><tr><td>train/total_flos</td><td>314615682432000.0</td></tr><tr><td>train/train_loss</td><td>0.42989</td></tr><tr><td>train/train_runtime</td><td>128.7777</td></tr><tr><td>train/train_samples_per_second</td><td>49.698</td></tr><tr><td>train/train_steps_per_second</td><td>1.553</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">vague-sweep-14</strong> at: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/0yjl9okn' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/0yjl9okn</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230728_110950-0yjl9okn/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3g1c1jf7 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tper_device_train_batch_size: 64\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230728_111236-3g1c1jf7</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/3g1c1jf7' target=\"_blank\">silver-sweep-15</a></strong> to <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/3g1c1jf7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/3g1c1jf7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'per_device_train_batch_size' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/200 03:37, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>0.558200</td>\n","      <td>0.591705</td>\n","      <td>0.766250</td>\n","      <td>0.755007</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.467400</td>\n","      <td>0.490211</td>\n","      <td>0.797500</td>\n","      <td>0.798012</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.314400</td>\n","      <td>0.426215</td>\n","      <td>0.831250</td>\n","      <td>0.829488</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.409400</td>\n","      <td>0.402221</td>\n","      <td>0.845000</td>\n","      <td>0.845159</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.120100</td>\n","      <td>0.402254</td>\n","      <td>0.850000</td>\n","      <td>0.850403</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.144700</td>\n","      <td>0.399734</td>\n","      <td>0.856250</td>\n","      <td>0.856014</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.042400</td>\n","      <td>0.410040</td>\n","      <td>0.860000</td>\n","      <td>0.859999</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.113200</td>\n","      <td>0.418501</td>\n","      <td>0.855000</td>\n","      <td>0.854816</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▃▆▇▇███</td></tr><tr><td>eval/f1</td><td>▁▄▆▇▇███</td></tr><tr><td>eval/loss</td><td>█▄▂▁▁▁▁▂</td></tr><tr><td>eval/runtime</td><td>▃▁▇▂▃█▁▃</td></tr><tr><td>eval/samples_per_second</td><td>▆█▂▇▆▁█▆</td></tr><tr><td>eval/steps_per_second</td><td>▆█▂▇▆▁█▆</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▇▇▆▅▅▄▄▅▄▄▂▃▃▃▂▂▃▂▃▂▂▂▂▃▂▂▂▁▂▂▁▁▁▁▁▁▁▂▂</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.855</td></tr><tr><td>eval/f1</td><td>0.85482</td></tr><tr><td>eval/loss</td><td>0.4185</td></tr><tr><td>eval/runtime</td><td>3.6368</td></tr><tr><td>eval/samples_per_second</td><td>219.971</td></tr><tr><td>eval/steps_per_second</td><td>13.748</td></tr><tr><td>train/epoch</td><td>4.0</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1132</td></tr><tr><td>train/total_flos</td><td>629231364864000.0</td></tr><tr><td>train/train_loss</td><td>0.30807</td></tr><tr><td>train/train_runtime</td><td>213.7196</td></tr><tr><td>train/train_samples_per_second</td><td>59.892</td></tr><tr><td>train/train_steps_per_second</td><td>0.936</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">silver-sweep-15</strong> at: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/3g1c1jf7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/3g1c1jf7</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230728_111236-3g1c1jf7/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xkjb3g2l with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tper_device_train_batch_size: 64\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.25\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230728_111644-xkjb3g2l</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/xkjb3g2l' target=\"_blank\">honest-sweep-16</a></strong> to <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/xkjb3g2l' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/xkjb3g2l</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'per_device_train_batch_size' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='151' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [151/200 02:36 < 00:51, 0.95 it/s, Epoch 3/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>0.558900</td>\n","      <td>0.591253</td>\n","      <td>0.765000</td>\n","      <td>0.753855</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.468200</td>\n","      <td>0.490228</td>\n","      <td>0.798750</td>\n","      <td>0.799156</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.317800</td>\n","      <td>0.426917</td>\n","      <td>0.832500</td>\n","      <td>0.830694</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.410900</td>\n","      <td>0.403470</td>\n","      <td>0.846250</td>\n","      <td>0.846377</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.121800</td>\n","      <td>0.403005</td>\n","      <td>0.848750</td>\n","      <td>0.849202</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.143800</td>\n","      <td>0.401253</td>\n","      <td>0.855000</td>\n","      <td>0.854712</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/200 03:39, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>0.558900</td>\n","      <td>0.591253</td>\n","      <td>0.765000</td>\n","      <td>0.753855</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.468200</td>\n","      <td>0.490228</td>\n","      <td>0.798750</td>\n","      <td>0.799156</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.317800</td>\n","      <td>0.426917</td>\n","      <td>0.832500</td>\n","      <td>0.830694</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.410900</td>\n","      <td>0.403470</td>\n","      <td>0.846250</td>\n","      <td>0.846377</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.121800</td>\n","      <td>0.403005</td>\n","      <td>0.848750</td>\n","      <td>0.849202</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.143800</td>\n","      <td>0.401253</td>\n","      <td>0.855000</td>\n","      <td>0.854712</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.042700</td>\n","      <td>0.411972</td>\n","      <td>0.858750</td>\n","      <td>0.858786</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.112700</td>\n","      <td>0.420169</td>\n","      <td>0.852500</td>\n","      <td>0.852294</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▄▆▇▇███</td></tr><tr><td>eval/f1</td><td>▁▄▆▇▇███</td></tr><tr><td>eval/loss</td><td>█▄▂▁▁▁▁▂</td></tr><tr><td>eval/runtime</td><td>█▅▁▆▂▃▅▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▄█▃▇▅▄█</td></tr><tr><td>eval/steps_per_second</td><td>▁▄█▃▇▅▄█</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▇▇▆▅▅▄▄▅▄▄▂▃▃▃▂▂▃▂▃▂▂▂▂▃▂▂▂▁▂▂▁▁▁▁▁▁▁▂▂</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.8525</td></tr><tr><td>eval/f1</td><td>0.85229</td></tr><tr><td>eval/loss</td><td>0.42017</td></tr><tr><td>eval/runtime</td><td>3.5409</td></tr><tr><td>eval/samples_per_second</td><td>225.93</td></tr><tr><td>eval/steps_per_second</td><td>14.121</td></tr><tr><td>train/epoch</td><td>4.0</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1127</td></tr><tr><td>train/total_flos</td><td>629231364864000.0</td></tr><tr><td>train/train_loss</td><td>0.30851</td></tr><tr><td>train/train_runtime</td><td>214.9029</td></tr><tr><td>train/train_samples_per_second</td><td>59.562</td></tr><tr><td>train/train_steps_per_second</td><td>0.931</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">honest-sweep-16</strong> at: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/xkjb3g2l' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/xkjb3g2l</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230728_111644-xkjb3g2l/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rnjx6du0 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tper_device_train_batch_size: 128\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.7"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230728_112100-rnjx6du0</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/rnjx6du0' target=\"_blank\">peach-sweep-17</a></strong> to <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/rnjx6du0' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/rnjx6du0</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'per_device_train_batch_size' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/200 06:38, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>0.616000</td>\n","      <td>0.528648</td>\n","      <td>0.785000</td>\n","      <td>0.781218</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.309500</td>\n","      <td>0.422889</td>\n","      <td>0.831250</td>\n","      <td>0.831444</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.218300</td>\n","      <td>0.432609</td>\n","      <td>0.840000</td>\n","      <td>0.841677</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.064300</td>\n","      <td>0.401695</td>\n","      <td>0.857500</td>\n","      <td>0.857022</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.061700</td>\n","      <td>0.493376</td>\n","      <td>0.853750</td>\n","      <td>0.852633</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.052500</td>\n","      <td>0.523972</td>\n","      <td>0.840000</td>\n","      <td>0.840600</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.015600</td>\n","      <td>0.493834</td>\n","      <td>0.860000</td>\n","      <td>0.860186</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.016100</td>\n","      <td>0.496551</td>\n","      <td>0.857500</td>\n","      <td>0.857884</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▆█▇▆██</td></tr><tr><td>eval/f1</td><td>▁▅▆█▇▆██</td></tr><tr><td>eval/loss</td><td>█▂▃▁▆█▆▆</td></tr><tr><td>eval/runtime</td><td>█▂▁▂▅▇▂▅</td></tr><tr><td>eval/samples_per_second</td><td>▁▇█▇▄▂▇▄</td></tr><tr><td>eval/steps_per_second</td><td>▁▇█▇▄▂▇▄</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>██▆▅▅▄▃▃▃▃▂▃▂▂▂▂▂▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.8575</td></tr><tr><td>eval/f1</td><td>0.85788</td></tr><tr><td>eval/loss</td><td>0.49655</td></tr><tr><td>eval/runtime</td><td>3.8428</td></tr><tr><td>eval/samples_per_second</td><td>208.181</td></tr><tr><td>eval/steps_per_second</td><td>13.011</td></tr><tr><td>train/epoch</td><td>8.0</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0161</td></tr><tr><td>train/total_flos</td><td>1258462729728000.0</td></tr><tr><td>train/train_loss</td><td>0.2113</td></tr><tr><td>train/train_runtime</td><td>396.4235</td></tr><tr><td>train/train_samples_per_second</td><td>64.577</td></tr><tr><td>train/train_steps_per_second</td><td>0.505</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">peach-sweep-17</strong> at: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/rnjx6du0' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/rnjx6du0</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230728_112100-rnjx6du0/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ekj4imha with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tper_device_train_batch_size: 128\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.25\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.7"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230728_112825-ekj4imha</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/ekj4imha' target=\"_blank\">sweet-sweep-18</a></strong> to <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/christian-159/distilBERT_finetuning' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/sweeps/uahb15q7</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/ekj4imha' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/ekj4imha</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'per_device_train_batch_size' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/200 06:38, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>0.616100</td>\n","      <td>0.528935</td>\n","      <td>0.785000</td>\n","      <td>0.781218</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.309300</td>\n","      <td>0.422393</td>\n","      <td>0.831250</td>\n","      <td>0.831444</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.216900</td>\n","      <td>0.431455</td>\n","      <td>0.843750</td>\n","      <td>0.845229</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.063900</td>\n","      <td>0.401518</td>\n","      <td>0.857500</td>\n","      <td>0.857033</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.061700</td>\n","      <td>0.490218</td>\n","      <td>0.851250</td>\n","      <td>0.850211</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.056400</td>\n","      <td>0.518607</td>\n","      <td>0.840000</td>\n","      <td>0.840807</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.017100</td>\n","      <td>0.492759</td>\n","      <td>0.857500</td>\n","      <td>0.857725</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.015800</td>\n","      <td>0.493250</td>\n","      <td>0.856250</td>\n","      <td>0.856615</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▇█▇▆██</td></tr><tr><td>eval/f1</td><td>▁▆▇█▇▆██</td></tr><tr><td>eval/loss</td><td>█▂▃▁▆▇▆▆</td></tr><tr><td>eval/runtime</td><td>▄▁▁▅█▅▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▄█▇▄▁▄██</td></tr><tr><td>eval/steps_per_second</td><td>▄█▇▄▁▄██</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>██▆▅▅▄▃▃▃▃▂▃▂▂▂▂▂▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.85625</td></tr><tr><td>eval/f1</td><td>0.85662</td></tr><tr><td>eval/loss</td><td>0.49325</td></tr><tr><td>eval/runtime</td><td>3.5331</td></tr><tr><td>eval/samples_per_second</td><td>226.43</td></tr><tr><td>eval/steps_per_second</td><td>14.152</td></tr><tr><td>train/epoch</td><td>8.0</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0158</td></tr><tr><td>train/total_flos</td><td>1258462729728000.0</td></tr><tr><td>train/train_loss</td><td>0.21156</td></tr><tr><td>train/train_runtime</td><td>395.4688</td></tr><tr><td>train/train_samples_per_second</td><td>64.733</td></tr><tr><td>train/train_steps_per_second</td><td>0.506</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">sweet-sweep-18</strong> at: <a href='https://wandb.ai/christian-159/distilBERT_finetuning/runs/ekj4imha' target=\"_blank\">https://wandb.ai/christian-159/distilBERT_finetuning/runs/ekj4imha</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230728_112825-ekj4imha/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Fyti4mqDoDY1"},"execution_count":null,"outputs":[]}]}